[
  {
    "objectID": "maps.html",
    "href": "maps.html",
    "title": "EVCI maps",
    "section": "",
    "text": "show_map\n\n show_map (urban_area:str, request_id='')\n\nThis function reads corresponding shape file and plots the points\nArguments:\nurban_area: a string describing the urban area to be analyzed request_id: a string with session/request ID\nReturns:\nNone\n\nshow_map(\"goa\",\"abc124\")"
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "EVCI analysis",
    "section": "",
    "text": "run_episode (charging_type, r, ui_inputs, s_df, txt, OUTPUT_PATH,\n              urban_area, request_id, report={}, cluster_th=0,\n              cluster=False)\n\nThis function runs a full episode of analysis on a set of sites.\nArguments:\n\ncharging_type: a string indicating opportunity or destination charging\nr: dictionary of global parameters read from the excel files\nui_inputs: json object of user selected inputs from the UI\ns_df: pre-processed geopandas dataframe with each point stored as shapely point object\ntxt: a string that identifies the episode (e.g. initial, final, with_cluster etc)\nOUTPUT_PATH: the directory path where the generated output files will be stored\nurban_area: a string indicating the urban area being analyzed (e.g goa)\nrequest_id: a string specific to a user session\nreport: a dictionary holding the progress report\ncluster_th: cluster threshold value (0 to 1)\ncluster: a boolean that decides if clustering will be performed. Default False\n\nReturns:\n\ns_u_df dataframe with computed utilization values for each site.\nreport: dictionary with interim report\n\n\n\n\n\n\n analyze_sites (request_id, urban_area:str, ui_inputs)\n\nThe function analyzes sites specified as part of a corridor.\nArguments:\n\nrequest_id: a string that specific to a user session\nurban_area: a string that identifies the urban area being analyzed (e.g. goa)\nui_inputs: json object of user selected inputs from the UI\n\nReturns:\nreturn_analysis: a dataframe containing the initial and clustered analysis for opportunity charging and destination charging separately."
  },
  {
    "objectID": "analysis.html#import-libraries",
    "href": "analysis.html#import-libraries",
    "title": "EVCI analysis",
    "section": "",
    "text": "run_episode (charging_type, r, ui_inputs, s_df, txt, OUTPUT_PATH,\n              urban_area, request_id, report={}, cluster_th=0,\n              cluster=False)\n\nThis function runs a full episode of analysis on a set of sites.\nArguments:\n\ncharging_type: a string indicating opportunity or destination charging\nr: dictionary of global parameters read from the excel files\nui_inputs: json object of user selected inputs from the UI\ns_df: pre-processed geopandas dataframe with each point stored as shapely point object\ntxt: a string that identifies the episode (e.g. initial, final, with_cluster etc)\nOUTPUT_PATH: the directory path where the generated output files will be stored\nurban_area: a string indicating the urban area being analyzed (e.g goa)\nrequest_id: a string specific to a user session\nreport: a dictionary holding the progress report\ncluster_th: cluster threshold value (0 to 1)\ncluster: a boolean that decides if clustering will be performed. Default False\n\nReturns:\n\ns_u_df dataframe with computed utilization values for each site.\nreport: dictionary with interim report\n\n\n\n\n\n\n analyze_sites (request_id, urban_area:str, ui_inputs)\n\nThe function analyzes sites specified as part of a corridor.\nArguments:\n\nrequest_id: a string that specific to a user session\nurban_area: a string that identifies the urban area being analyzed (e.g. goa)\nui_inputs: json object of user selected inputs from the UI\n\nReturns:\nreturn_analysis: a dataframe containing the initial and clustered analysis for opportunity charging and destination charging separately."
  },
  {
    "objectID": "analysis.html#example",
    "href": "analysis.html#example",
    "title": "EVCI analysis",
    "section": "Example",
    "text": "Example\n\n# Inputs from UI\nui_inputs = { \n    \"planning_scenario\": \"Public places\",\n    \"years_of_analysis\": [1,2,3],\n    \"Ai\": 50,\n    \"Li\": 1500,\n    \"Bipc\": 0.25,\n    \"Birate\": 3.5,\n    \"Eg\": 5.5,\n    \"backoff_factor\": 1,\n    \"cabling_cost\": 500,\n    \"capex_2W\": 2500,\n    \"capex_3WS\": 112000,\n    \"capex_4WS\": 250000,\n    \"capex_4WF\": 1500000,\n    \"hoarding cost\": 900000,\n    \"kiosk_cost\": 180000,\n    \"year1_conversion\": 0.02,\n    \"year2_conversion\": 0.05,\n    \"year3_conversion\": 0.1,\n    \"holiday_percentage\": 0.3,\n    \"fast_charging\": 0.3,\n    \"slow_charging\": 0.15,\n    \"cluster\": False,\n    \"cluster_th\": 0.2,\n    \"plot_dendrogram\": False\n}\n\ns_u_df = analyze_sites('abc124','panaji', ui_inputs)\n\nReading input files...done.\n\nOpportunity_charging Analysis\n9\n\nInitial Analysis\n________________\n\nNumber of sites: 9/9\nTotal capex charges = INR Cr 1.93\nTotal opex charges = INR Cr 5.85\nTotal Margin = INR Cr 47162.17\nconfirmed sites with utilization &gt; 20%: 2\n{'no_site': '9/9', 'capex': '1.93', 'opex': '5.85', 'margin': '47162.17', 'confirmed_utilization': '20%: 2'}\nconfirmed sites with utilization &gt; 20%: 2\n\nDestination_charging Analysis\n9\n\nInitial Analysis\n________________\n\nNumber of sites: 9/9\nTotal capex charges = INR Cr 1.93\nTotal opex charges = INR Cr 3.12\nTotal Margin = INR Cr 1.12\nconfirmed sites with utilization &gt; 20%: 0\n{'no_site': '9/9', 'capex': '1.93', 'opex': '3.12', 'margin': '1.12', 'confirmed_utilization': '20%: 0'}\nconfirmed sites with utilization &gt; 20%: 0\n\n\n100%|██████████| 9/9 [00:16&lt;00:00,  1.85s/it]\n100%|██████████| 9/9 [00:03&lt;00:00,  2.48it/s]\n\n\n\nfig, (ax1,ax2) = plt.subplots(1,2, figsize=(10,3))\ns_u_df['opportunity_charging']['initial'].hist(column='utilization',ax=ax1);\ns_u_df['destination_charging']['initial'].hist(column='utilization',ax=ax2);\nax1.title.set_text('Opportunity charging')\nax2.title.set_text('Destination charging')\nplt.tight_layout()\n\n\n\n\n\n#s_u_df.hist(column='unserviced')"
  },
  {
    "objectID": "analysis.html#with-clustering",
    "href": "analysis.html#with-clustering",
    "title": "EVCI analysis",
    "section": "With Clustering",
    "text": "With Clustering\n\n# Inputs from UI\nui_inputs = { \n    \"planning_scenario\": \"Public places\",\n    \"years_of_analysis\": [1,2,3],\n    \"Ai\": 50,\n    \"Li\": 1500,\n    \"Bipc\": 0.25,\n    \"Birate\": 3.5,\n    \"Eg\": 5.5,\n    \"backoff_factor\": 1,\n    \"cabling_cost\": 500000,\n    \"capex_2W\": 2500,\n    \"capex_3WS\": 112000,\n    \"capex_4WS\": 250000,\n    \"capex_4WF\": 1500000,\n    \"hoarding cost\": 900000,\n    \"kiosk_cost\": 180000,\n    \"year1_conversion\": 0.02,\n    \"year2_conversion\": 0.05,\n    \"year3_conversion\": 0.1,\n    \"holiday_percentage\": 0.3,\n    \"fast_charging\": 0.3,\n    \"slow_charging\": 0.15,\n    \"cluster\": True,\n    \"cluster_th\": 0.2,\n    \"plot_dendrogram\": True\n}\n\ns_u_df = analyze_sites('abc124','panaji', ui_inputs)\n\nReading input files...done.\n\nOpportunity_charging Analysis\n9\n\nInitial Analysis\n________________\n\nNumber of sites: 9/9\nTotal capex charges = INR Cr 2.07\nTotal opex charges = INR Cr 5.85\nTotal Margin = INR Cr 47162.17\nconfirmed sites with utilization &gt; 20%: 2\n{'no_site': '9/9', 'capex': '2.07', 'opex': '5.85', 'margin': '47162.17', 'confirmed_utilization': '20%: 2'}\ncandidates for clustering:  7\nconfirmed sites with utilization &gt; 20%: 2\nfinal list:  4\n\nCluster Analysis\n________________\n\nNumber of sites: 4/9\nTotal capex charges = INR Cr 0.94\nTotal opex charges = INR Cr 5.52\nTotal Margin = INR Cr 71369.85\nconfirmed sites with utilization &gt; 20%: 4\n{'no_site': '4/9', 'capex': '0.94', 'opex': '5.52', 'margin': '71369.85', 'confirmed_utilization': '20%: 4'}\n\nDestination_charging Analysis\n9\n\nInitial Analysis\n________________\n\nNumber of sites: 9/9\nTotal capex charges = INR Cr 2.07\nTotal opex charges = INR Cr 3.12\nTotal Margin = INR Cr 1.12\nconfirmed sites with utilization &gt; 20%: 0\n{'no_site': '9/9', 'capex': '2.07', 'opex': '3.12', 'margin': '1.12', 'confirmed_utilization': '20%: 0'}\ncandidates for clustering:  9\nconfirmed sites with utilization &gt; 20%: 0\nfinal list:  3\n\nCluster Analysis\n________________\n\nNumber of sites: 3/9\nTotal capex charges = INR Cr 0.71\nTotal opex charges = INR Cr 1.04\nTotal Margin = INR Cr 0.37\nconfirmed sites with utilization &gt; 20%: 0\n{'no_site': '3/9', 'capex': '0.71', 'opex': '1.04', 'margin': '0.37', 'confirmed_utilization': '20%: 0'}\n\n\n100%|██████████| 9/9 [00:16&lt;00:00,  1.87s/it]\n100%|██████████| 4/4 [00:07&lt;00:00,  1.91s/it]\n100%|██████████| 9/9 [00:03&lt;00:00,  2.42it/s]\n100%|██████████| 3/3 [00:01&lt;00:00,  2.51it/s]\n\n\n\n\n\n\n\n\n\n# after clustering\nfig, (ax1,ax2) = plt.subplots(1,2, figsize=(10,3))\ns_u_df['opportunity_charging']['cluster'].hist(column='utilization',ax=ax1);\ns_u_df['destination_charging']['cluster'].hist(column='utilization',ax=ax2);\nax1.title.set_text('Opportunity charging')\nax2.title.set_text('Destination charging')\nplt.tight_layout()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EVCI Siting Tool",
    "section": "",
    "text": "pip install evci_tool"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "EVCI Siting Tool",
    "section": "",
    "text": "pip install evci_tool"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "EVCI Siting Tool",
    "section": "How to use",
    "text": "How to use\nThe model inputs are provided in the form of excel files (xlsx). The analyze_sites() is the entry level function and completes the analysis for specified corridor\n\nfrom evci_tool.config import *\nfrom evci_tool.model import *\nfrom evci_tool.analysis import *\n\nui_inputs = { \n    \"planning_scenario\": \"Fleet hubs\",\n    \"years_of_analysis\": [1,2,3],\n    \"Ai\": 50,\n    \"Li\": 1500,\n    \"Bipc\": .25,\n    \"Birate\": 3.5,\n    \"Eg\": 5.5,\n    \"backoff_factor\":1,\n    \"cabling_cost\": 500,\n    \"capex_2W\": 2500,\n    \"capex_3WS\": 112000,\n    \"capex_4WS\": 250000,\n    \"capex_4WF\": 1500000,\n    \"hoarding cost\": 900000,\n    \"kiosk_cost\": 180000,\n    \"year1_conversion\": 0.02,\n    \"year2_conversion\": 0.05,\n    \"year3_conversion\": 0.1,\n    \"holiday_percentage\": 0.3,\n    \"fast_charging\": 0.3,\n    \"slow_charging\": 0.15,\n    \"cluster\": False,\n    \"cluster_th\": 0.2,\n    \"plot_dendrogram\": False\n}\n\n\nu_df = analyze_sites ('abc124','goa',ui_inputs)\n\nReading input files...done.\n\nOpportunity_charging Analysis\n\nInitial Analysis\n________________\n\nNumber of sites: 13/20\nTotal capex charges = INR Cr 9.85\nTotal opex charges = INR Cr 35.03\nTotal Margin = INR Cr 11447.83\nconfirmed sites with utilization &gt; 20%: 10\n{'no_site': '13/20', 'capex': '9.85', 'opex': '35.03', 'margin': '11447.83', 'confirmed_utilization': '20%: 10'}\nconfirmed sites with utilization &gt; 20%: 10\n\nDestination_charging Analysis\n\nInitial Analysis\n________________\n\nNumber of sites: 13/20\nTotal capex charges = INR Cr 9.85\nTotal opex charges = INR Cr 27.52\nTotal Margin = INR Cr 8632.20\nconfirmed sites with utilization &gt; 20%: 10\n{'no_site': '13/20', 'capex': '9.85', 'opex': '27.52', 'margin': '8632.20', 'confirmed_utilization': '20%: 10'}\nconfirmed sites with utilization &gt; 20%: 10\nsuccess request:  b'{\"ack\":1}'\n\n\n100%|██████████| 13/13 [00:33&lt;00:00,  2.59s/it]\n100%|██████████| 13/13 [00:09&lt;00:00,  1.40it/s]\n\n\n\nimport matplotlib.pyplot as plt\n\nfig, (ax1,ax2) = plt.subplots(1,2, figsize=(10,3))\nu_df['opportunity_charging']['initial'].hist(column='utilization',ax=ax1);\nu_df['destination_charging']['initial'].hist(column='utilization',ax=ax2);\nax1.title.set_text('Opportunity charging')\nax2.title.set_text('Destination charging')\nplt.tight_layout()"
  },
  {
    "objectID": "config.html",
    "href": "config.html",
    "title": "EVCI config - for urban areas",
    "section": "",
    "text": "model.xlsx - This contains all the global parameters that are model specific. They remain valid for every urban area that is being analyzed.\nsites.xlsx - This contains a list of sites, with their latitude and longitude for analysis. This is an initial list of sites. This file needs to be created for each urban area. Sites can be filtered based on the planning scenarios.\ntraffic.xlsx - This contains typical traffic profiles for each site category around the sites for each urban area. This file is used to assign a traffic profile to each site based on its category.\ngrid.xlsx - This contains information about neighboring distribution transformers from where the chargers deployed at each site will draw power from.\nparking.xlsx - This contains multiple worksheets, each corresponding to a parking profile. Each site is assigned a parking profile based on its category.\n\n\nRead input data\n\n\ncheck_files_availability\n\n check_files_availability (urban_area:str, input_path='data/sites/')\n\nThis function simply checks if all the required input files mentioned above are available.\nArguments:\n\nuban_area: a string that identifies the urban area being analyzed (e.g. ‘goa’)\ninput_path: a string denoting base directory under which input files (xlsx and others) are available for analysis. Default is '/mnt/sites/'\n\nReturns:\nfiles_not_found: a list of filenames not found in the default and/or specified path.\n\n\n\nsetup_and_read_data\n\n setup_and_read_data (urban_area:str, input_path='data/sites/',\n                      output_path='data/analysis/', request_id='')\n\nThis function sets up paths and reads input excel files for a specified corridor\nArguments:\n\nurban_area: a string that identifies the urban area being analyzed (e.g. ‘goa’)\ninput_path: a string denoting base directory under which input files (xlsx and other) are available for analysis. Default is '/mnt/sites/'\noutput_path: a string denoting base directory under which output files will be stored. Default is '/mnt/analysis/'\nrequest_id: a string denoting the request ID (specific to user credentials)\n\nReturns:\n\nmodel: dataframe of model parameters (from model.xlsx)\nsites: dataframe of sites (from sites.xlsx)\ntraffic: dataframe of traffic profiles (from traffic.xlsx)\ngrid: dataframe of grid parameters (from grid.xlsx)\nparking: dataframe of parking profiles (from parking.xlsx)\nINPUT_PATH: a string indicating the input_path (e.g. input/goa/)\nOUTPUT_PATH: a string indicating the output path (e.g. output/goa/)\n\n\n#example_usage\nfiles_not_fouund = check_files_availability('panaji',input_path='data/sites/')\nfiles_not_fouund\n\n[]\n\n\n\n#example usage\nm,s,t,g,p,i,o = setup_and_read_data('panaji', input_path=\"data/sites/\", output_path=\"data/analysis/\")\n\n\n\n\nData availability check\nLet’s check if the input excel sheets provided have the correctly named worksheets within them.\n\n\ndata_availability_check\n\n data_availability_check (m, s, t, g, p)\n\nThis function checks if the excel files contain the mandatory worksheets.\nArguments:\n\nm: dataframe of model parameters (from model.xlsx)\ns: dataframe of sites (from sites.xlsx)\nt: dataframe of traffic profile (from traffic.xlsx)\ng: dataframe of grid parameters (from grid.xlsx)\np: dataframe of parking parameters (from parking.xlsx)\n\nReturns:\nA list of xlsx file names wiht missing mandatory sheets\n\ndata_availability_check(m,s,t,g,p)\n\n[]\n\n\n\n\n\nData integrity check\nLet’s now check if any of the mandatory columns in each of the worksheets are all empty!\n\n\ndata_integrity_check\n\n data_integrity_check (m, s, t, g, p, verbose=False)\n\nThis function checks for integrity of excel data by checking missing values.\nArguments:\n\nm: dataframe of model parameters (from model.xlsx)\ns: dataframe of sites (from sites.xlsx)\nt: dataframe of traffic profile (from traffic.xlsx)\ng: dataframe of grid parameters (from grid.xlsx)\n\nReturns:\nA dictionary of missing columns with their corresponding xlsx filename and worksheet name.\n\ndata_integrity_check(m,s,t,g,p)\n\n[{'planning_scenarios': [],\n  'charger_details': [],\n  'chargers_site_categories': [],\n  'chargers_opportunity_charging': [],\n  'battery_specific': [],\n  'others': []},\n {'sites': []},\n {'TF1': [], 'TF2': [], 'TF3': []},\n {'grid': []},\n {'BD': [], 'FH': [], 'PP': []}]\n\n\n\n# verbose output\ndata_integrity_check(m,s,t,g,p,verbose=True)\n\n\n\n\ndata_missing_check\n\n data_missing_check (sid, file, input_path='data/sites/')\n\nFunction checks for missing values in the excel data\n\n\n\nRead global variables from xlsx\n\n\nget_category\n\n get_category (sid, input_path='data/sites/')\n\nFunction fetch site categories available in sites.xlsx file\n\n\n\nget_grid_data\n\n get_grid_data (s, g)\n\nArguments:\n\ns: dataframe of sites (from sites.xlsx)\ng: dataframe of grid profile (from grid.xlsx)\n\nReturns:\nAugmented data frame ‘s’ with lat,long of nearest transformer and its distance in kms from each site\n\ndi = get_grid_data(s,g)\ndi.head()\n\n\n\n\n\n\n\n\nName\nAddress\nLongitude\nLatitude\nSite category\nNo. of charger bundles opportunity charging\nNo. of charger bundles destination charging\nParking lot size\nPeak opportunity charging traffic\nOpportunity charging traffic profile\n...\nUpfront cost per sqm (kiosk)\nYearly cost per sqm (kiosk)\nUpfront cost per sqm (hoarding)\nYearly cost per sqm (hoarding)\nBattery swap available\ngeometry\nTransformer name\nTransformer longitude\nTransformer latitude\nTransformer distance\n\n\n\n\n0\nMiramar Beach\nNorth Beach Parking\n73.808845\n15.483450\nPP\n1\n1\n0\n70\nTF1\n...\n0\n135000\n0\n0\n0\nPOINT (73.80885 15.48345)\nCLUBE TENNIS DE GASPER\n73.809155\n15.482570\n0.103548\n\n\n1\nCaculo Mall\nMalls\n73.817859\n15.486461\nPP\n1\n1\n0\n70\nTF1\n...\n0\n135000\n0\n0\n0\nPOINT (73.81786 15.48646)\nCACULO MALL\n73.818163\n15.486739\n0.045180\n\n\n2\nPanjim KTC Bus Stand\nTransit locations - Bus stands\n73.838266\n15.496108\nPP\n1\n1\n0\n70\nTF1\n...\n0\n135000\n0\n0\n0\nPOINT (73.83827 15.49611)\nKTC Bus stand\n73.838134\n15.495092\n0.114134\n\n\n3\nMulti-Level Car Park GTDC\nCESL Proposed Panaji locatio\n73.836559\n15.499065\nPP\n1\n1\n0\n70\nTF1\n...\n0\n135000\n0\n0\n0\nPOINT (73.83656 15.49906)\nManaging Director(GTDC)\n73.836074\n15.499388\n0.063610\n\n\n4\nINOX Goa\nCESL Proposed Panaji locatio\n73.821097\n15.498726\nPP\n1\n1\n0\n70\nTF1\n...\n0\n135000\n0\n0\n0\nPOINT (73.82110 15.49873)\nINOX LEISURE LTD (MULTIPLEX)\n73.821407\n15.498623\n0.035425\n\n\n\n\n5 rows × 27 columns\n\n\n\n\n\n\nread_globals\n\n read_globals (m, s, t, g, p, charging_type, ui_inputs)\n\nThis function returns all global parameters read from the xlsx.\nArguments:\n\nm: dataframe of model parameters (from model.xlsx)\ns: dataframe of sites (from sites.xlsx)\nt: dataframe of traffic profile (from traffic.xlsx)\ng: dataframe of grid parameters (from grid.xlsx)\np: dataframe of parking parameters (from parking.xlsx)\ncharging_type: a string opportunity_charging or destination_charging\nui_inputs: dictionary of all parameters selected by use from the frontend with the UI\n\nReturns:\nA dictionary with all hyperparameters required for the model to run\n\n# example usage\n\nui_inputs = { \n    \"planning_scenario\": \"Public places\",\n    \"years_of_analysis\": 2,\n    \"Ai\": 50,\n    \"Li\": 1500,\n    \"Bipc\": .25,\n    \"Birate\": 3.5,\n    \"MK\": .15,\n    \"Eg\": 5.5,\n    \"cabling_cost\":500,\n    \"capex_2W\": 2500,\n    \"capex_3WS\": 112000,\n    \"capex_4WS\": 250000,\n    \"capex_4WF\": 1500000,\n    \"hoarding cost\": 900000,\n    \"kiosk_cost\": 180000,\n    \"year1_conversion\": 0.02,\n    \"year2_conversion\": 0.05,\n    \"year3_conversion\": 0.1,\n    \"holiday_percentage\": 0.3,\n    \"fast_charging\": 0.3,\n    \"slow_charging\": 0.15,\n}\n\nr = read_globals(m,s,t,g,p, 'opportunity_charging', ui_inputs)\nprint(r['Kj'])\nprint(r['charger_types'])\nprint(r['Cij']['4WS'])\n\n{'2W': 40000, '4WS': 200000, '4WF': 1825000}\n['2W', '4WS', '4WF']\n[1, 1, 1, 1, 1, 1, 1, 1, 1]"
  },
  {
    "objectID": "model.html",
    "href": "model.html",
    "title": "EVCI siting model",
    "section": "",
    "text": "score\n\n score (charging_type, r, s_df, s_df_distances, j, i, hj, k, backoff=True,\n        backoff_factor=1)\n\nThis function computes the utilization score of each site.\nArguments:\n\ncharging_type: a string indicating opportunity or destination charging.\nr: a dictionary of global parameters read from the xlsx files.\ns_df_distances: a dataframe of Euclidean distances of each site from all others. (NxN matrix)\nj: string indicating specific charger type\ni: integer indicating a specific site\nhj:\nk: integer year (1, 2 or 3 of the policy)\nbackoff: a boolean indicating whether backoff should be incorporated\nbackoff_factor: a float weighting factor for the backoff (mostly empirically selected)\n\nReturns:\n\nnorm_uw: float indicating normalized utilization on a typical working day\nnorm_uh: float indicating normalized utilization on a typical holiday\nnorm_vw: float indicating number of vehicles not utilizing charging on a working day\nnorm_vh: float indicating number of vehicles not utilizing charging on a holiday\n\n\n\n\ncapex\n\n capex (r, i)\n\nThis function computes the capex requirements of each site\nArguments:\n\nr: a dictionary of global parameters read from the xlsx files.\ni: integer indicating a specific site\n\nReturns:\ninteger. Capex value for a given site\n\n\n\nopex\n\n opex (charging_type, r, s_df, s_df_distances, i)\n\nThis function computes the opex for each site.\nArguments:\n\ncharging_type: a string indicating opportunity or destination charging.\nr: a dictionary of global parameters read from the xlsx files.\ns_df: a dataframe of the sites\ns_df_distances: a dataframe of Euclidean distances of each site from all others. (NxN matrix)\ni: integer indicating a specific site\n\nReturns:\ninteger opex value for a given site\n\n\n\nmargin\n\n margin (charging_type, r, s_df, s_df_distances, i)\n\nThis function computes the margins per site.\nArguments:\n\ncharging_type: a string indicating opportunity or destination charging.\nr: a dictionary of global parameters read from the xlsx files.\ns_df: a dataframe of sites\ns_df_distances: a dataframe of Euclidean distances of each site from all others. (NxN matrix)\ni: integer indicating a specific site\n\nReturns:\ninteger margin value of a site\n\n\n\nrun_analysis\n\n run_analysis (charging_type, r, s_df, backoff_factor=1, sid='', aid='',\n               cluster=False, stage='')\n\nThis function runs analysis for a given set of sites.\nArguments:\n\ncharging_type: a string indicating whether opportunity or destination charging\nr: a dictionary of global variables read from Excel files\ns_df: pre-processed geopandas dataframe with each point stored as shapely point object\nbackoff_factor: a float value of backoff to cater for neighborhood (empirical)\nsid: session id\naid: id\ncluster: a boolean indicating if clustering is performed\nstage: string indicating whether initial or clustered stage\n\nReturns:\nA dataframe of utilization values for all sites."
  }
]